### VOLUMES IN KUBERNETES ###

# Data, in docker, exists with the container, when the container is destroyed its data is losed forever
# To avoid this we attach a volume to the containers when they are created

# Like containers, pod in kubernetes are transient
# When a POD is created to process data and then deleted, the data processed by the pod it gets deleted as well
# For this we attach a volume to the POD.
# Data generated by the POD is now stored in the volume and when the pod is deleted, the data remains

# Let's look at a simple implementation of volumes
# We have a single node kubernetes cluster
# We create a simple POD that generates a random number between 1 and 100 and writes that to /opt/number.out file
# To retain the number when the POD is deleted, we create a volume
# When you create a volume you can choose to configure it storage in different ways
# In this example we specify the /data directory as source of the volume
apiVersion: v1
kind: Pod
metadata:
  name: my-pod-with-volume
spec:
  containers:
  - image: alpine
    name: alpine
    command: ["/bin/sh", "-c"]
    args: ["shuf -i 0-100 -n 1 >> /opt/number.out;"]
    volumeMounts:
    - mountPath: /opt
      name: data-volume
  volumes:
  - name: data-volume
    hostPath:
      path: /data
      type: Directory

# In this example we have created a volumes called "data-volume" that use the host-path /data to save data
# To access it from the container we mount the volume to a directory inside the container
# To do this we use the volumeMounts field in container entry to mount the data-volume to the directory /opt of the container
# The random number file will now be written to /opt mount inside the container which happen to be in data-volume
# data-volume is in fact /data directory on the host
# When the pod gets deleted the file still remain on the hosts under /data

# let's look volume storage options
# hostPath options is used to configure a directory in the host as storage space for the volume
# This works fine on a single node! However is not recommended for use in a multi node cluster
# This because the PODs would use the /data directory on all the nodes, and expect all of them to be the same and have the same data.
# Since they are on different servers, they are in fact not the same
# You can configure some kind of external replicated cluster storage solutions

# Kubernetes supports several types of standard stroage solutions like NFS, glusterFS, Flocker, ScaleIO and public cloud solutions like AWS EBS, Azure Disk or Google Persistent Disk
# For example configure an AWS Elastic Block Store volume as storage options for the volume
# Replace hostPath field of the volumes section with awsElasticBlockStore field along with the volumeID and fsType

volumes:
- name: data-volume
  awsElasticBlockStore:
    volumeID: <volume-id>
    fsType: ext4
















#
